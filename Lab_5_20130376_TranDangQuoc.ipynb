{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/couqdev/MachineLearning/blob/main/Lab_5_20130376_TranDangQuoc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with **SVM** to classification tasks and compare its performance with other competitive algorithms. In general, **SVM** is one of the most popular and widely used supervised machine learning algorithms.\n",
        "\n",
        "*   **Deadline: 23:59, 17/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/MachineLeaning'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjEmBQappIeV",
        "outputId": "140e9272-fbdd-4b27-f0df-8e2657afc4ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/MachineLeaning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from prettytable import PrettyTable\n",
        "import sklearn.metrics as metrics\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   1.1.\tApply SVM algorithm to above dataset using linear kernel.\n",
        "*   1.2.\tCompare the obtained results with other competitive algorithms (Logistic Regression, Decision Tree, kNN) based on metrics: accuracy, precision, recall, f1 measures.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer  = datasets.load_breast_cancer()\n",
        "\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)\n",
        "# SVM\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "acc1=  metrics.accuracy_score(y_test, y_pred)\n",
        "pre1 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec1 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Accuracy:\",acc1)\n",
        "print(\"Precision:\", pre1)\n",
        "print(\"Recall:\", rec1)\n",
        "print(\"F1:\", f1_1)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa69822-524b-4a1d-9f43-4ac0d2934cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9532163742690059\n",
            "Precision: 0.9562651331719128\n",
            "Recall: 0.9431216931216931\n",
            "F1: 0.9490312965722802\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.93        63\n",
            "           1       0.95      0.98      0.96       108\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.96      0.94      0.95       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "classifier = LogisticRegression(random_state = 1,solver='lbfgs',max_iter=10000)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "acc2 = metrics.accuracy_score(y_test, y_pred)\n",
        "pre2 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec2 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_2 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6texNrkwYne",
        "outputId": "a5fc5814-92eb-4478-b456-e8e90e08bb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.90      0.93        63\n",
            "           1       0.95      0.97      0.96       108\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.95      0.94      0.94       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "KNN = KNeighborsClassifier(28)\n",
        "KNN.fit(X_train, y_train)\n",
        "y_predKNN = KNN.predict(X_test)\n",
        "pre3 = metrics.precision_score(y_test, y_predKNN, average='macro')\n",
        "rec3 = metrics.recall_score(y_test, y_predKNN, average='macro')\n",
        "f1_3 = metrics.f1_score(y_test, y_predKNN, average='macro')\n",
        "acc3  = metrics.accuracy_score(y_test, y_predKNN)\n",
        "print(metrics.classification_report(y_test, y_predKNN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8-QXQJyy13x",
        "outputId": "2ff934f8-1d0d-41b7-d619-41322d7a0981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.83      0.87        63\n",
            "           1       0.90      0.96      0.93       108\n",
            "\n",
            "    accuracy                           0.91       171\n",
            "   macro avg       0.92      0.89      0.90       171\n",
            "weighted avg       0.91      0.91      0.91       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "pre4 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec4 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_4 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "acc4  = metrics.accuracy_score(y_test, y_pred)\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrD9fPS-1TTr",
        "outputId": "a8a45665-dda9-4dbb-ac1d-f12ee099bead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.89      0.92        63\n",
            "           1       0.94      0.97      0.95       108\n",
            "\n",
            "    accuracy                           0.94       171\n",
            "   macro avg       0.94      0.93      0.94       171\n",
            "weighted avg       0.94      0.94      0.94       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = PrettyTable(['','accuracy', 'precision', 'recall', 'f1'])\n",
        "t.add_row(['SVM',round(acc1, 3),round(pre1,3),round(rec1, 3),round(f1_1,3)])\n",
        "t.add_row(['Logistic Regression',round(acc2, 3),round(pre2,3),round(rec2, 3),round(f1_2,3)])\n",
        "t.add_row(['KNN',round(acc3, 3),round(pre3,3),round(rec3, 3),round(f1_3,3)])\n",
        "t.add_row(['Decision Tree',round(acc4, 3),round(pre4,3),round(rec4, 3),round(f1_4,3)])\n",
        "print(t)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jc5vRhir6Mm",
        "outputId": "fdf74b1a-eb76-4ff3-b632-bb22895b5bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+----------+-----------+--------+-------+\n",
            "|                     | accuracy | precision | recall |   f1  |\n",
            "+---------------------+----------+-----------+--------+-------+\n",
            "|         SVM         |  0.953   |   0.956   | 0.943  | 0.949 |\n",
            "| Logistic Regression |  0.947   |   0.948   | 0.938  | 0.943 |\n",
            "|         KNN         |  0.912   |   0.916   | 0.894  | 0.903 |\n",
            "|    Decision Tree    |  0.924   |   0.926   |  0.91  | 0.917 |\n",
            "+---------------------+----------+-----------+--------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "\n",
        "*   1.1.\tPerform SVM algorithm to **Iris dataset** using **linear kernel**.\n",
        "*   1.2.\tCompare the obtained results in 1.1 with SVM using other kernels (**Polynomial Kernel, Gaussian Kernel, Sigmoid Kernel, Radial Basis Function Kernel**). Some metrics could be used: accuracy, precision, recall, f1 measures\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.load_iris()\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)\n",
        "# SVM Linear Kernel:\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "acc1=  metrics.accuracy_score(y_test, y_pred)\n",
        "pre1 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec1 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Accuracy:\",acc1)\n",
        "print(\"Precision:\", pre1)\n",
        "print(\"Recall:\", rec1)\n",
        "print(\"F1:\", f1_1)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d45e1a-91b7-4dca-953b-98f85776ca27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        18\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Polynomial Kernel:\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "acc2=  metrics.accuracy_score(y_test, y_pred)\n",
        "pre2 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec2 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_2 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Accuracy:\",acc1)\n",
        "print(\"Precision:\", pre1)\n",
        "print(\"Recall:\", rec1)\n",
        "print(\"F1:\", f1_1)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhkrhn0W55wz",
        "outputId": "ae78ad8c-c43e-4315-dadf-5b152105035e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9761904761904763\n",
            "Recall: 0.9814814814814815\n",
            "F1: 0.9781305114638448\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      0.94      0.97        18\n",
            "           2       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM sigmoid Kernel:\n",
        "clf = svm.SVC(kernel='sigmoid')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "acc3=  metrics.accuracy_score(y_test, y_pred)\n",
        "pre3 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec3 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_3 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Accuracy:\",acc1)\n",
        "print(\"Precision:\", pre1)\n",
        "print(\"Recall:\", rec1)\n",
        "print(\"F1:\", f1_1)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVPvRwKv6COe",
        "outputId": "cfd7d433-cd07-4bb5-931d-f32a22e79c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.28888888888888886\n",
            "Precision: 0.09629629629629628\n",
            "Recall: 0.3333333333333333\n",
            "F1: 0.14942528735632185\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        14\n",
            "           1       0.00      0.00      0.00        18\n",
            "           2       0.29      1.00      0.45        13\n",
            "\n",
            "    accuracy                           0.29        45\n",
            "   macro avg       0.10      0.33      0.15        45\n",
            "weighted avg       0.08      0.29      0.13        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM RBF Kernel:\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "acc4=  metrics.accuracy_score(y_test, y_pred)\n",
        "pre4 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec4 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_4 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Accuracy:\",acc1)\n",
        "print(\"Precision:\", pre1)\n",
        "print(\"Recall:\", rec1)\n",
        "print(\"F1:\", f1_1)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Jtvdnf80Ie",
        "outputId": "32cd66b0-b744-4e7f-e82c-862279a5f307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9761904761904763\n",
            "Recall: 0.9814814814814815\n",
            "F1: 0.9781305114638448\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      0.94      0.97        18\n",
            "           2       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = PrettyTable(['','accuracy', 'precision', 'recall', 'f1'])\n",
        "t.add_row(['linear',round(acc1, 3),round(pre1,3),round(rec1, 3),round(f1_1,3)])\n",
        "t.add_row(['Poly',round(acc2, 3),round(pre2,3),round(rec2, 3),round(f1_2,3)])\n",
        "t.add_row(['sigmoid',round(acc3, 3),round(pre3,3),round(rec3, 3),round(f1_3,3)])\n",
        "t.add_row(['rbf',round(acc4, 3),round(pre4,3),round(rec4, 3),round(f1_4,3)])\n",
        "print(t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp5SNe_f-A87",
        "outputId": "06dc5c74-749c-41fe-f363-4c4c1437a23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+-----------+--------+-------+\n",
            "|         | accuracy | precision | recall |   f1  |\n",
            "+---------+----------+-----------+--------+-------+\n",
            "|  linear |  0.978   |   0.976   | 0.981  | 0.978 |\n",
            "|   Poly  |  0.978   |   0.976   | 0.981  | 0.978 |\n",
            "| sigmoid |  0.978   |   0.976   | 0.981  | 0.978 |\n",
            "|   rbf   |  0.956   |   0.956   | 0.956  | 0.956 |\n",
            "+---------+----------+-----------+--------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with mnist dataset based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_mnist = datasets.load_digits()\n",
        "X = data_mnist.data\n",
        "y = data_mnist.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "acc1 = metrics.accuracy_score(y_test, y_pred)\n",
        "precision1 = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall1 = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_1 = metrics.f1_score(y_test, y_pred, average='micro')\n"
      ],
      "metadata": {
        "id": "vqEYt5l1R28C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train, y_train)\n",
        "y_pred = dtree.predict(X_test)\n",
        "acc_2 = round((metrics.accuracy_score(y_test, y_pred)),4)\n",
        "precision_2 = round((metrics.precision_score(y_test, y_pred, average = 'macro')),4)\n",
        "f1_2 = round((metrics.f1_score(y_test, y_pred, average = 'macro')),4)\n",
        "recall_2 = round((metrics.recall_score(y_test, y_pred, average = 'macro')),4)\n",
        "\n"
      ],
      "metadata": {
        "id": "iRy6EyLYG14q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 29)\n",
        "KNN.fit(X_train, y_train)\n",
        "y_pred = KNN.predict(X_test)\n",
        "\n",
        "acc_3 = round(metrics.accuracy_score(y_test, y_pred),4)\n",
        "precision_3 = round(metrics.precision_score(y_test, y_pred, average = 'micro'),4)\n",
        "f1_3 = round(metrics.f1_score(y_test, y_pred, average = 'micro'),4)\n",
        "recall_3 = round(metrics.recall_score(y_test, y_pred, average = 'micro'),4)\n",
        "\n"
      ],
      "metadata": {
        "id": "VtXbDkSJG57S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression(random_state = 0, max_iter=10000)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc_4 = round((metrics.accuracy_score(y_test, y_pred)),4)\n",
        "precision_4 = round((metrics.precision_score(y_test, y_pred, average = 'macro')),4)\n",
        "f1_4 = round((metrics.f1_score(y_test, y_pred, average = 'macro')),4)\n",
        "recall_4 = round((metrics.recall_score(y_test, y_pred, average = 'macro')),4)\n",
        "\n"
      ],
      "metadata": {
        "id": "swnnFqg4G9QA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = PrettyTable(['','acc','precision','recall','f1'])\n",
        "t.add_row(['SMV',acc1,precision1,recall1,f1_1])\n",
        "t.add_row(['Decision Tree',acc_2,precision_2,recall_2,f1_2])\n",
        "t.add_row(['kNN',acc_3,precision_3,recall_3,f1_3])\n",
        "t.add_row(['Logistic Regression',acc_4,precision_4,recall_4,f1_4])\n",
        "\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt_RPhM5G_Ew",
        "outputId": "e89a4eaf-2652-429d-a4a0-356873ded1e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                     |        acc         |     precision      |       recall       |         f1         |\n",
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         SMV         | 0.9851851851851852 | 0.9851851851851852 | 0.9851851851851852 | 0.9851851851851852 |\n",
            "|    Decision Tree    |       0.8574       |        0.86        |       0.8613       |       0.8587       |\n",
            "|         kNN         |       0.9667       |       0.9667       |       0.9667       |       0.9667       |\n",
            "| Logistic Regression |       0.9685       |       0.9673       |       0.9681       |       0.9674       |\n",
            "+---------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with **credit card dataset** based on accuracy, precision, recall, f1 measures.\n",
        "\n",
        "*   Give some comments on the obtained results\n",
        "*   Identify issues with dataset, and propose the solutions to these issues\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "dataset1 = pd.read_csv(\"creditcard.csv\")\n",
        "dataset1.columns\n",
        "X = dataset1.head(5000)[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
        "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
        "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]\n",
        "y = dataset1.head(5000)[['Class']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=3)"
      ],
      "metadata": {
        "id": "bh97WgFEa3Cb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Linear Kernel:\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "acc1=  metrics.accuracy_score(y_test, y_pred)\n",
        "pre1 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec1 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "print(\"Accuracy:\",acc1)\n",
        "print(\"Precision:\", pre1)\n",
        "print(\"Recall:\", rec1)\n",
        "print(\"F1:\", f1_1)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DatLtTVxc8aZ",
        "outputId": "632f5591-f0fc-47cb-dcb3-908245260a2f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9993333333333333\n",
            "Precision: 0.49966666666666665\n",
            "Recall: 0.5\n",
            "F1: 0.49983327775925307\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1499\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           1.00      1500\n",
            "   macro avg       0.50      0.50      0.50      1500\n",
            "weighted avg       1.00      1.00      1.00      1500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "classifier = LogisticRegression(random_state = 1,solver='lbfgs',max_iter=10000)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "acc2 = metrics.accuracy_score(y_test, y_pred)\n",
        "pre2 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec2 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_2 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRb3pT7OJedB",
        "outputId": "8645696f-8436-4159-dfd4-06ec4d902d13"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1499\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           1.00      1500\n",
            "   macro avg       0.50      0.50      0.50      1500\n",
            "weighted avg       1.00      1.00      1.00      1500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "KNN = KNeighborsClassifier(28)\n",
        "KNN.fit(X_train, y_train)\n",
        "y_predKNN = KNN.predict(X_test)\n",
        "pre3 = metrics.precision_score(y_test, y_predKNN, average='macro')\n",
        "rec3 = metrics.recall_score(y_test, y_predKNN, average='macro')\n",
        "f1_3 = metrics.f1_score(y_test, y_predKNN, average='macro')\n",
        "acc3  = metrics.accuracy_score(y_test, y_predKNN)\n",
        "print(metrics.classification_report(y_test, y_predKNN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbX39QgZJmwL",
        "outputId": "d045ed48-2422-421b-f90e-fea680f5e966"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1499\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           1.00      1500\n",
            "   macro avg       0.50      0.50      0.50      1500\n",
            "weighted avg       1.00      1.00      1.00      1500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "pre4 = metrics.precision_score(y_test, y_pred, average='macro')\n",
        "rec4 = metrics.recall_score(y_test, y_pred, average='macro')\n",
        "f1_4 = metrics.f1_score(y_test, y_pred, average='macro')\n",
        "acc4  = metrics.accuracy_score(y_test, y_pred)\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_sfRzMAJtb_",
        "outputId": "c5e10dde-9fde-4573-eae4-a04a3f316b4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1499\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           1.00      1500\n",
            "   macro avg       0.50      0.50      0.50      1500\n",
            "weighted avg       1.00      1.00      1.00      1500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = PrettyTable(['','accuracy', 'precision', 'recall', 'f1'])\n",
        "t.add_row(['SVM',round(acc1, 4),round(pre1,4),round(rec1, 3),round(f1_1,3)])\n",
        "t.add_row(['Logistic Regression',round(acc2, 3),round(pre2,3),round(rec2, 3),round(f1_2,3)])\n",
        "t.add_row(['KNN',round(acc3, 3),round(pre3,3),round(rec3, 3),round(f1_3,3)])\n",
        "t.add_row(['Decision Tree',round(acc4, 3),round(pre4,3),round(rec4, 3),round(f1_4,3)])\n",
        "print(t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri1DMBHPJw7W",
        "outputId": "8a75e6ee-eb3e-46a8-d61e-633934433982"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+----------+-----------+--------+-----+\n",
            "|                     | accuracy | precision | recall |  f1 |\n",
            "+---------------------+----------+-----------+--------+-----+\n",
            "|         SVM         |  0.9993  |   0.4997  |  0.5   | 0.5 |\n",
            "| Logistic Regression |  0.999   |    0.5    |  0.5   | 0.5 |\n",
            "|         KNN         |  0.999   |    0.5    |  0.5   | 0.5 |\n",
            "|    Decision Tree    |  0.999   |    0.5    |  0.5   | 0.5 |\n",
            "+---------------------+----------+-----------+--------+-----+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}